{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb7a99be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T11:19:54.326049Z",
     "iopub.status.busy": "2021-09-01T11:19:54.325333Z",
     "iopub.status.idle": "2021-09-01T11:19:58.606284Z",
     "shell.execute_reply": "2021-09-01T11:19:58.605335Z",
     "shell.execute_reply.started": "2021-08-31T16:23:27.541434Z"
    },
    "papermill": {
     "duration": 4.302444,
     "end_time": "2021-09-01T11:19:58.606433",
     "exception": false,
     "start_time": "2021-09-01T11:19:54.303989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D, Input, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b727fbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T11:19:58.628650Z",
     "iopub.status.busy": "2021-09-01T11:19:58.626992Z",
     "iopub.status.idle": "2021-09-01T11:19:58.629336Z",
     "shell.execute_reply": "2021-09-01T11:19:58.629795Z",
     "shell.execute_reply.started": "2021-08-31T16:23:33.993138Z"
    },
    "papermill": {
     "duration": 0.016135,
     "end_time": "2021-09-01T11:19:58.629924",
     "exception": false,
     "start_time": "2021-09-01T11:19:58.613789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "seed = 77\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed549bb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T11:19:58.648572Z",
     "iopub.status.busy": "2021-09-01T11:19:58.647821Z",
     "iopub.status.idle": "2021-09-01T11:19:58.649964Z",
     "shell.execute_reply": "2021-09-01T11:19:58.650359Z",
     "shell.execute_reply.started": "2021-08-31T16:23:34.005711Z"
    },
    "papermill": {
     "duration": 0.013882,
     "end_time": "2021-09-01T11:19:58.650480",
     "exception": false,
     "start_time": "2021-09-01T11:19:58.636598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    (x_train, y_train), (x_val, y_val) = tf.keras.datasets.cifar10.load_data()\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    x_val = x_val.astype('float32') / 255\n",
    "    # convert labels to categorical samples\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "    y_val = tf.keras.utils.to_categorical(y_val, num_classes=10)\n",
    "    return ((x_train, y_train), (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60635b90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T11:19:58.666366Z",
     "iopub.status.busy": "2021-09-01T11:19:58.665595Z",
     "iopub.status.idle": "2021-09-01T11:20:04.592428Z",
     "shell.execute_reply": "2021-09-01T11:20:04.591948Z",
     "shell.execute_reply.started": "2021-08-31T16:23:34.018974Z"
    },
    "papermill": {
     "duration": 5.935477,
     "end_time": "2021-09-01T11:20:04.592562",
     "exception": false,
     "start_time": "2021-09-01T11:19:58.657085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test,y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85ef1712",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T11:20:04.652502Z",
     "iopub.status.busy": "2021-09-01T11:20:04.651653Z",
     "iopub.status.idle": "2021-09-01T11:20:04.654362Z",
     "shell.execute_reply": "2021-09-01T11:20:04.653908Z",
     "shell.execute_reply.started": "2021-08-31T16:23:42.875451Z"
    },
    "papermill": {
     "duration": 0.037325,
     "end_time": "2021-09-01T11:20:04.654478",
     "exception": false,
     "start_time": "2021-09-01T11:20:04.617153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class zconv2d(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_dim,rate=0.5, kernel_size=(3, 3), strides=(1, 1, 1, 1), **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.mask=None\n",
    "        self.rate=rate\n",
    "        super(zconv2d, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        kernel_shape = tf.TensorShape((self.kernel_size[0], self.kernel_size[1], input_shape[-1], self.output_dim))\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=kernel_shape,\n",
    "                                      initializer=tf.initializers.he_normal(),\n",
    "                                      trainable=True,regularizer=tf.keras.regularizers.l2(1e-4))\n",
    "        \n",
    "        self.b = tf.Variable(\n",
    "                initial_value=tf.initializers.Zeros()(shape=(self.output_dim,), \n",
    "                                                    dtype='float32'),\n",
    "                trainable=True)\n",
    "        \n",
    "        self.mask=tf.Variable(tf.cast(\n",
    "            (tf.random.uniform(\n",
    "                shape=(self.kernel_size[0], self.kernel_size[1],input_shape[-1],\n",
    "                       self.output_dim),minval=0, maxval=1,dtype=tf.float32)<self.rate),tf.int32)\n",
    "                             ,trainable=False)\n",
    "        super(zconv2d, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.nn.conv2d(inputs, filters=tf.multiply(self.kernel,tf.cast(self.mask,self.kernel.dtype)),\n",
    "                              strides=self.strides, padding='SAME')\n",
    "        x=x+self.b\n",
    "        #output=tf.nn.relu(x)\n",
    "        return x\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1] = self.output_dim\n",
    "        return tf.TensorShape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a92ecc77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T11:20:04.725743Z",
     "iopub.status.busy": "2021-09-01T11:20:04.715174Z",
     "iopub.status.idle": "2021-09-01T14:25:40.841580Z",
     "shell.execute_reply": "2021-09-01T14:25:40.841115Z"
    },
    "papermill": {
     "duration": 11136.164055,
     "end_time": "2021-09-01T14:25:40.841732",
     "exception": false,
     "start_time": "2021-09-01T11:20:04.677677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zconv2d (zconv2d)               (None, 32, 32, 32)   1760        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 32)   128         zconv2d[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zconv2d_1 (zconv2d)             (None, 32, 32, 32)   18464       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 32)   128         zconv2d_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zconv2d_2 (zconv2d)             (None, 32, 32, 32)   18464       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 32)   128         zconv2d_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 32, 32)   0           activation[0][0]                 \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 32)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zconv2d_3 (zconv2d)             (None, 32, 32, 32)   18464       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 32)   128         zconv2d_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 32)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zconv2d_4 (zconv2d)             (None, 32, 32, 32)   18464       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 32)   128         zconv2d_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 32)   0           activation_2[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 32)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "zconv2d_5 (zconv2d)             (None, 32, 32, 32)   18464       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 32)   128         zconv2d_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zconv2d_6 (zconv2d)             (None, 32, 32, 32)   18464       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 32)   128         zconv2d_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 32)   0           activation_4[0][0]               \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 32)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "zconv2d_7 (zconv2d)             (None, 16, 16, 64)   36928       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 64)   256         zconv2d_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zconv2d_8 (zconv2d)             (None, 16, 16, 64)   73792       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 16, 16, 64)   2112        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 64)   256         zconv2d_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 16, 64)   0           conv2d[0][0]                     \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 64)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "zconv2d_9 (zconv2d)             (None, 16, 16, 64)   73792       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 64)   256         zconv2d_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zconv2d_10 (zconv2d)            (None, 16, 16, 64)   73792       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 64)   256         zconv2d_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 64)   0           activation_8[0][0]               \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 64)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "zconv2d_11 (zconv2d)            (None, 16, 16, 64)   73792       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 64)   256         zconv2d_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zconv2d_12 (zconv2d)            (None, 16, 16, 64)   73792       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 64)   256         zconv2d_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 64)   0           activation_10[0][0]              \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 64)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "zconv2d_13 (zconv2d)            (None, 8, 8, 128)    147584      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 128)    512         zconv2d_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 128)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zconv2d_14 (zconv2d)            (None, 8, 8, 128)    295040      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 8, 8, 128)    8320        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 128)    512         zconv2d_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 128)    0           conv2d_1[0][0]                   \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 128)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "zconv2d_15 (zconv2d)            (None, 8, 8, 128)    295040      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 128)    512         zconv2d_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 128)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zconv2d_16 (zconv2d)            (None, 8, 8, 128)    295040      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 128)    512         zconv2d_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 128)    0           activation_14[0][0]              \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 128)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "zconv2d_17 (zconv2d)            (None, 8, 8, 128)    295040      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 128)    512         zconv2d_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 128)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zconv2d_18 (zconv2d)            (None, 8, 8, 128)    295040      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 8, 128)    512         zconv2d_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 128)    0           activation_16[0][0]              \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 128)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 128)    0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 128)          0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           1290        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,158,442\n",
      "Trainable params: 1,085,770\n",
      "Non-trainable params: 1,072,672\n",
      "__________________________________________________________________________________________________\n",
      "ResNet20v1\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 65s 35ms/step - loss: 1.8406 - accuracy: 0.4104 - val_loss: 1.4172 - val_accuracy: 0.5621\n",
      "Epoch 2/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 1.1706 - accuracy: 0.6535 - val_loss: 1.3459 - val_accuracy: 0.6222\n",
      "Epoch 3/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.9831 - accuracy: 0.7254 - val_loss: 1.5340 - val_accuracy: 0.6082\n",
      "Epoch 4/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.8853 - accuracy: 0.7681 - val_loss: 1.0367 - val_accuracy: 0.7291\n",
      "Epoch 5/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.8337 - accuracy: 0.7857 - val_loss: 0.8741 - val_accuracy: 0.7839\n",
      "Epoch 6/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.7981 - accuracy: 0.8000 - val_loss: 1.0192 - val_accuracy: 0.7414\n",
      "Epoch 7/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.7683 - accuracy: 0.8134 - val_loss: 0.8563 - val_accuracy: 0.7887\n",
      "Epoch 8/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.7367 - accuracy: 0.8263 - val_loss: 1.1434 - val_accuracy: 0.7070\n",
      "Epoch 9/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.7106 - accuracy: 0.8338 - val_loss: 0.9716 - val_accuracy: 0.7649\n",
      "Epoch 10/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 0.6988 - accuracy: 0.8417 - val_loss: 0.9030 - val_accuracy: 0.7806\n",
      "Epoch 11/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.6764 - accuracy: 0.8499 - val_loss: 0.8310 - val_accuracy: 0.8059\n",
      "Epoch 12/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 0.6627 - accuracy: 0.8542 - val_loss: 0.7707 - val_accuracy: 0.8271\n",
      "Epoch 13/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 56s 35ms/step - loss: 0.6557 - accuracy: 0.8585 - val_loss: 0.8464 - val_accuracy: 0.8012\n",
      "Epoch 14/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.6387 - accuracy: 0.8617 - val_loss: 0.9661 - val_accuracy: 0.7671\n",
      "Epoch 15/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.6349 - accuracy: 0.8647 - val_loss: 0.7436 - val_accuracy: 0.8344\n",
      "Epoch 16/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.6251 - accuracy: 0.8698 - val_loss: 0.7778 - val_accuracy: 0.8277\n",
      "Epoch 17/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.6176 - accuracy: 0.8708 - val_loss: 0.8390 - val_accuracy: 0.8045\n",
      "Epoch 18/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.6054 - accuracy: 0.8769 - val_loss: 0.7766 - val_accuracy: 0.8217\n",
      "Epoch 19/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 57s 37ms/step - loss: 0.6016 - accuracy: 0.8771 - val_loss: 0.7368 - val_accuracy: 0.8403\n",
      "Epoch 20/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 57s 37ms/step - loss: 0.5986 - accuracy: 0.8787 - val_loss: 0.7214 - val_accuracy: 0.8378\n",
      "Epoch 21/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.5964 - accuracy: 0.8785 - val_loss: 0.8055 - val_accuracy: 0.8247\n",
      "Epoch 22/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 0.5864 - accuracy: 0.8824 - val_loss: 0.8323 - val_accuracy: 0.8219\n",
      "Epoch 23/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5887 - accuracy: 0.8840 - val_loss: 0.8485 - val_accuracy: 0.8045\n",
      "Epoch 24/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 57s 37ms/step - loss: 0.5747 - accuracy: 0.8860 - val_loss: 0.6572 - val_accuracy: 0.8660\n",
      "Epoch 25/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 0.5679 - accuracy: 0.8901 - val_loss: 0.9817 - val_accuracy: 0.7739\n",
      "Epoch 26/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.5683 - accuracy: 0.8903 - val_loss: 0.7290 - val_accuracy: 0.8471\n",
      "Epoch 27/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.5707 - accuracy: 0.8893 - val_loss: 0.7808 - val_accuracy: 0.8255\n",
      "Epoch 28/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5625 - accuracy: 0.8922 - val_loss: 0.8733 - val_accuracy: 0.8039\n",
      "Epoch 29/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.5616 - accuracy: 0.8927 - val_loss: 0.7176 - val_accuracy: 0.8490\n",
      "Epoch 30/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 58s 37ms/step - loss: 0.5584 - accuracy: 0.8940 - val_loss: 0.8146 - val_accuracy: 0.8206\n",
      "Epoch 31/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5487 - accuracy: 0.8963 - val_loss: 0.8893 - val_accuracy: 0.8103\n",
      "Epoch 32/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 59s 37ms/step - loss: 0.5442 - accuracy: 0.8959 - val_loss: 1.2271 - val_accuracy: 0.7366\n",
      "Epoch 33/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5338 - accuracy: 0.9009 - val_loss: 0.8609 - val_accuracy: 0.8066\n",
      "Epoch 34/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5426 - accuracy: 0.8983 - val_loss: 0.8296 - val_accuracy: 0.8246\n",
      "Epoch 35/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 59s 37ms/step - loss: 0.5443 - accuracy: 0.8966 - val_loss: 0.7245 - val_accuracy: 0.8434\n",
      "Epoch 36/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5324 - accuracy: 0.9009 - val_loss: 0.7422 - val_accuracy: 0.8427\n",
      "Epoch 37/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 59s 38ms/step - loss: 0.5293 - accuracy: 0.9014 - val_loss: 0.6843 - val_accuracy: 0.8565\n",
      "Epoch 38/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.5302 - accuracy: 0.8998 - val_loss: 0.7068 - val_accuracy: 0.8463\n",
      "Epoch 39/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.5317 - accuracy: 0.8995 - val_loss: 0.7067 - val_accuracy: 0.8540\n",
      "Epoch 40/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 58s 37ms/step - loss: 0.5308 - accuracy: 0.9014 - val_loss: 0.7117 - val_accuracy: 0.8444\n",
      "Epoch 41/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.5239 - accuracy: 0.9037 - val_loss: 0.7890 - val_accuracy: 0.8251\n",
      "Epoch 42/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 0.5214 - accuracy: 0.9038 - val_loss: 0.7775 - val_accuracy: 0.8307\n",
      "Epoch 43/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5150 - accuracy: 0.9062 - val_loss: 0.6830 - val_accuracy: 0.8602\n",
      "Epoch 44/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.5099 - accuracy: 0.9078 - val_loss: 0.9638 - val_accuracy: 0.7920\n",
      "Epoch 45/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 59s 38ms/step - loss: 0.5185 - accuracy: 0.9042 - val_loss: 0.7154 - val_accuracy: 0.8494\n",
      "Epoch 46/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.5170 - accuracy: 0.9052 - val_loss: 0.7992 - val_accuracy: 0.8242\n",
      "Epoch 47/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 56s 35ms/step - loss: 0.5147 - accuracy: 0.9055 - val_loss: 0.6794 - val_accuracy: 0.8630\n",
      "Epoch 48/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 58s 37ms/step - loss: 0.5131 - accuracy: 0.9078 - val_loss: 0.6760 - val_accuracy: 0.8596\n",
      "Epoch 49/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.5133 - accuracy: 0.9065 - val_loss: 0.5971 - val_accuracy: 0.8820\n",
      "Epoch 50/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 0.5063 - accuracy: 0.9078 - val_loss: 0.6363 - val_accuracy: 0.8682\n",
      "Epoch 51/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.5067 - accuracy: 0.9088 - val_loss: 0.7378 - val_accuracy: 0.8407\n",
      "Epoch 52/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.5126 - accuracy: 0.9068 - val_loss: 0.8233 - val_accuracy: 0.8232\n",
      "Epoch 53/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 59s 38ms/step - loss: 0.5073 - accuracy: 0.9066 - val_loss: 0.7958 - val_accuracy: 0.8275\n",
      "Epoch 54/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.4956 - accuracy: 0.9114 - val_loss: 0.7555 - val_accuracy: 0.8382\n",
      "Epoch 55/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5005 - accuracy: 0.9093 - val_loss: 0.7747 - val_accuracy: 0.8308\n",
      "Epoch 56/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 58s 37ms/step - loss: 0.4936 - accuracy: 0.9119 - val_loss: 0.6526 - val_accuracy: 0.8655\n",
      "Epoch 57/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.4908 - accuracy: 0.9132 - val_loss: 0.7073 - val_accuracy: 0.8469\n",
      "Epoch 58/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.4921 - accuracy: 0.9110 - val_loss: 0.6672 - val_accuracy: 0.8576\n",
      "Epoch 59/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.4932 - accuracy: 0.9118 - val_loss: 0.8163 - val_accuracy: 0.8323\n",
      "Epoch 60/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4886 - accuracy: 0.9134 - val_loss: 0.6237 - val_accuracy: 0.8679\n",
      "Epoch 61/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 58s 37ms/step - loss: 0.4874 - accuracy: 0.9127 - val_loss: 0.7220 - val_accuracy: 0.8481\n",
      "Epoch 62/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.4909 - accuracy: 0.9139 - val_loss: 1.1087 - val_accuracy: 0.7522\n",
      "Epoch 63/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.4881 - accuracy: 0.9118 - val_loss: 0.7293 - val_accuracy: 0.8530\n",
      "Epoch 64/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.4790 - accuracy: 0.9153 - val_loss: 0.6597 - val_accuracy: 0.8624\n",
      "Epoch 65/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.4923 - accuracy: 0.9108 - val_loss: 0.7777 - val_accuracy: 0.8357\n",
      "Epoch 66/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 58s 37ms/step - loss: 0.4908 - accuracy: 0.9097 - val_loss: 0.7025 - val_accuracy: 0.8523\n",
      "Epoch 67/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.4912 - accuracy: 0.9123 - val_loss: 0.6697 - val_accuracy: 0.8659\n",
      "Epoch 68/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.4880 - accuracy: 0.9101 - val_loss: 0.6277 - val_accuracy: 0.8673\n",
      "Epoch 69/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.4830 - accuracy: 0.9134 - val_loss: 0.6720 - val_accuracy: 0.8587\n",
      "Epoch 70/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 0.4811 - accuracy: 0.9131 - val_loss: 0.9127 - val_accuracy: 0.8064\n",
      "Epoch 71/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 61s 39ms/step - loss: 0.4789 - accuracy: 0.9144 - val_loss: 0.7826 - val_accuracy: 0.8334\n",
      "Epoch 72/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.4786 - accuracy: 0.9153 - val_loss: 0.7928 - val_accuracy: 0.8295\n",
      "Epoch 73/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4777 - accuracy: 0.9134 - val_loss: 0.6893 - val_accuracy: 0.8587\n",
      "Epoch 74/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 56s 35ms/step - loss: 0.4733 - accuracy: 0.9163 - val_loss: 0.7026 - val_accuracy: 0.8565\n",
      "Epoch 75/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 0.4696 - accuracy: 0.9161 - val_loss: 0.6770 - val_accuracy: 0.8551\n",
      "Epoch 76/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 0.4691 - accuracy: 0.9158 - val_loss: 0.7293 - val_accuracy: 0.8512\n",
      "Epoch 77/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.4716 - accuracy: 0.9168 - val_loss: 0.7454 - val_accuracy: 0.8427\n",
      "Epoch 78/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.4655 - accuracy: 0.9183 - val_loss: 0.7247 - val_accuracy: 0.8459\n",
      "Epoch 79/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.4693 - accuracy: 0.9158 - val_loss: 0.6221 - val_accuracy: 0.8744\n",
      "Epoch 80/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.4750 - accuracy: 0.9152 - val_loss: 0.6396 - val_accuracy: 0.8661\n",
      "Epoch 81/200\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 61s 39ms/step - loss: 0.4643 - accuracy: 0.9162 - val_loss: 0.7663 - val_accuracy: 0.8334\n",
      "Epoch 82/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4071 - accuracy: 0.9385 - val_loss: 0.4949 - val_accuracy: 0.9114\n",
      "Epoch 83/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.3658 - accuracy: 0.9514 - val_loss: 0.4868 - val_accuracy: 0.9134\n",
      "Epoch 84/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.3415 - accuracy: 0.9582 - val_loss: 0.4776 - val_accuracy: 0.9172\n",
      "Epoch 85/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.3309 - accuracy: 0.9603 - val_loss: 0.4736 - val_accuracy: 0.9185\n",
      "Epoch 86/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 62s 40ms/step - loss: 0.3193 - accuracy: 0.9604 - val_loss: 0.4858 - val_accuracy: 0.9142\n",
      "Epoch 87/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.3078 - accuracy: 0.9630 - val_loss: 0.4667 - val_accuracy: 0.9161\n",
      "Epoch 88/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.3007 - accuracy: 0.9647 - val_loss: 0.4604 - val_accuracy: 0.9190\n",
      "Epoch 89/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2908 - accuracy: 0.9663 - val_loss: 0.4715 - val_accuracy: 0.9174\n",
      "Epoch 90/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2868 - accuracy: 0.9671 - val_loss: 0.4646 - val_accuracy: 0.9164\n",
      "Epoch 91/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 65s 41ms/step - loss: 0.2787 - accuracy: 0.9689 - val_loss: 0.4564 - val_accuracy: 0.9172\n",
      "Epoch 92/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2724 - accuracy: 0.9699 - val_loss: 0.4577 - val_accuracy: 0.9188\n",
      "Epoch 93/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2653 - accuracy: 0.9722 - val_loss: 0.4590 - val_accuracy: 0.9193\n",
      "Epoch 94/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2574 - accuracy: 0.9743 - val_loss: 0.4508 - val_accuracy: 0.9196\n",
      "Epoch 95/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2560 - accuracy: 0.9727 - val_loss: 0.4610 - val_accuracy: 0.9183\n",
      "Epoch 96/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.2530 - accuracy: 0.9737 - val_loss: 0.4571 - val_accuracy: 0.9187\n",
      "Epoch 97/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.2460 - accuracy: 0.9752 - val_loss: 0.4549 - val_accuracy: 0.9174\n",
      "Epoch 98/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2399 - accuracy: 0.9763 - val_loss: 0.4465 - val_accuracy: 0.9197\n",
      "Epoch 99/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2370 - accuracy: 0.9769 - val_loss: 0.4459 - val_accuracy: 0.9228\n",
      "Epoch 100/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2338 - accuracy: 0.9774 - val_loss: 0.4532 - val_accuracy: 0.9188\n",
      "Epoch 101/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 61s 39ms/step - loss: 0.2317 - accuracy: 0.9775 - val_loss: 0.4588 - val_accuracy: 0.9168\n",
      "Epoch 102/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 58s 37ms/step - loss: 0.2253 - accuracy: 0.9790 - val_loss: 0.4550 - val_accuracy: 0.9188\n",
      "Epoch 103/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2199 - accuracy: 0.9799 - val_loss: 0.4513 - val_accuracy: 0.9173\n",
      "Epoch 104/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2210 - accuracy: 0.9778 - val_loss: 0.4384 - val_accuracy: 0.9199\n",
      "Epoch 105/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2166 - accuracy: 0.9793 - val_loss: 0.4591 - val_accuracy: 0.9181\n",
      "Epoch 106/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 57s 37ms/step - loss: 0.2104 - accuracy: 0.9808 - val_loss: 0.4683 - val_accuracy: 0.9149\n",
      "Epoch 107/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 62s 40ms/step - loss: 0.2112 - accuracy: 0.9794 - val_loss: 0.4697 - val_accuracy: 0.9154\n",
      "Epoch 108/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2074 - accuracy: 0.9809 - val_loss: 0.4551 - val_accuracy: 0.9174\n",
      "Epoch 109/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2043 - accuracy: 0.9806 - val_loss: 0.4501 - val_accuracy: 0.9186\n",
      "Epoch 110/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.2018 - accuracy: 0.9813 - val_loss: 0.4519 - val_accuracy: 0.9176\n",
      "Epoch 111/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1953 - accuracy: 0.9836 - val_loss: 0.4402 - val_accuracy: 0.9201\n",
      "Epoch 112/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1948 - accuracy: 0.9823 - val_loss: 0.4483 - val_accuracy: 0.9185\n",
      "Epoch 113/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1922 - accuracy: 0.9828 - val_loss: 0.4613 - val_accuracy: 0.9175\n",
      "Epoch 114/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1905 - accuracy: 0.9831 - val_loss: 0.4550 - val_accuracy: 0.9184\n",
      "Epoch 115/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1867 - accuracy: 0.9839 - val_loss: 0.4549 - val_accuracy: 0.9197\n",
      "Epoch 116/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1859 - accuracy: 0.9836 - val_loss: 0.4601 - val_accuracy: 0.9192\n",
      "Epoch 117/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1831 - accuracy: 0.9837 - val_loss: 0.4513 - val_accuracy: 0.9193\n",
      "Epoch 118/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1864 - accuracy: 0.9820 - val_loss: 0.4446 - val_accuracy: 0.9203\n",
      "Epoch 119/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1807 - accuracy: 0.9841 - val_loss: 0.4518 - val_accuracy: 0.9216\n",
      "Epoch 120/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1765 - accuracy: 0.9846 - val_loss: 0.4504 - val_accuracy: 0.9198\n",
      "Epoch 121/200\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1761 - accuracy: 0.9845 - val_loss: 0.4638 - val_accuracy: 0.9183\n",
      "Epoch 122/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1705 - accuracy: 0.9868 - val_loss: 0.4391 - val_accuracy: 0.9233\n",
      "Epoch 123/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1670 - accuracy: 0.9884 - val_loss: 0.4385 - val_accuracy: 0.9236\n",
      "Epoch 124/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1652 - accuracy: 0.9891 - val_loss: 0.4379 - val_accuracy: 0.9242\n",
      "Epoch 125/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1663 - accuracy: 0.9886 - val_loss: 0.4375 - val_accuracy: 0.9218\n",
      "Epoch 126/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1629 - accuracy: 0.9895 - val_loss: 0.4357 - val_accuracy: 0.9236\n",
      "Epoch 127/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1618 - accuracy: 0.9896 - val_loss: 0.4358 - val_accuracy: 0.9240\n",
      "Epoch 128/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1588 - accuracy: 0.9915 - val_loss: 0.4357 - val_accuracy: 0.9242\n",
      "Epoch 129/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1612 - accuracy: 0.9899 - val_loss: 0.4347 - val_accuracy: 0.9242\n",
      "Epoch 130/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1614 - accuracy: 0.9897 - val_loss: 0.4381 - val_accuracy: 0.9225\n",
      "Epoch 131/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.1597 - accuracy: 0.9905 - val_loss: 0.4390 - val_accuracy: 0.9237\n",
      "Epoch 132/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1591 - accuracy: 0.9902 - val_loss: 0.4401 - val_accuracy: 0.9243\n",
      "Epoch 133/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1582 - accuracy: 0.9908 - val_loss: 0.4396 - val_accuracy: 0.9241\n",
      "Epoch 134/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1590 - accuracy: 0.9910 - val_loss: 0.4402 - val_accuracy: 0.9236\n",
      "Epoch 135/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1565 - accuracy: 0.9907 - val_loss: 0.4395 - val_accuracy: 0.9234\n",
      "Epoch 136/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1562 - accuracy: 0.9909 - val_loss: 0.4372 - val_accuracy: 0.9250\n",
      "Epoch 137/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1553 - accuracy: 0.9914 - val_loss: 0.4382 - val_accuracy: 0.9248\n",
      "Epoch 138/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1551 - accuracy: 0.9915 - val_loss: 0.4356 - val_accuracy: 0.9250\n",
      "Epoch 139/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1555 - accuracy: 0.9912 - val_loss: 0.4368 - val_accuracy: 0.9240\n",
      "Epoch 140/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1546 - accuracy: 0.9911 - val_loss: 0.4352 - val_accuracy: 0.9258\n",
      "Epoch 141/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 0.1528 - accuracy: 0.9923 - val_loss: 0.4396 - val_accuracy: 0.9230\n",
      "Epoch 142/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.1548 - accuracy: 0.9912 - val_loss: 0.4388 - val_accuracy: 0.9242\n",
      "Epoch 143/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.1544 - accuracy: 0.9913 - val_loss: 0.4391 - val_accuracy: 0.9243\n",
      "Epoch 144/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.1534 - accuracy: 0.9915 - val_loss: 0.4390 - val_accuracy: 0.9251\n",
      "Epoch 145/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1531 - accuracy: 0.9922 - val_loss: 0.4381 - val_accuracy: 0.9241\n",
      "Epoch 146/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1532 - accuracy: 0.9913 - val_loss: 0.4377 - val_accuracy: 0.9250\n",
      "Epoch 147/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1516 - accuracy: 0.9917 - val_loss: 0.4412 - val_accuracy: 0.9248\n",
      "Epoch 148/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1502 - accuracy: 0.9922 - val_loss: 0.4414 - val_accuracy: 0.9249\n",
      "Epoch 149/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1516 - accuracy: 0.9914 - val_loss: 0.4395 - val_accuracy: 0.9260\n",
      "Epoch 150/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1513 - accuracy: 0.9915 - val_loss: 0.4414 - val_accuracy: 0.9249\n",
      "Epoch 151/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 0.1515 - accuracy: 0.9918 - val_loss: 0.4405 - val_accuracy: 0.9253\n",
      "Epoch 152/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 0.1484 - accuracy: 0.9930 - val_loss: 0.4413 - val_accuracy: 0.9252\n",
      "Epoch 153/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1503 - accuracy: 0.9923 - val_loss: 0.4440 - val_accuracy: 0.9254\n",
      "Epoch 154/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1502 - accuracy: 0.9914 - val_loss: 0.4408 - val_accuracy: 0.9260\n",
      "Epoch 155/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1492 - accuracy: 0.9926 - val_loss: 0.4424 - val_accuracy: 0.9262\n",
      "Epoch 156/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1500 - accuracy: 0.9924 - val_loss: 0.4436 - val_accuracy: 0.9253\n",
      "Epoch 157/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1485 - accuracy: 0.9926 - val_loss: 0.4418 - val_accuracy: 0.9254\n",
      "Epoch 158/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1471 - accuracy: 0.9933 - val_loss: 0.4425 - val_accuracy: 0.9254\n",
      "Epoch 159/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1472 - accuracy: 0.9930 - val_loss: 0.4441 - val_accuracy: 0.9254\n",
      "Epoch 160/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1469 - accuracy: 0.9933 - val_loss: 0.4460 - val_accuracy: 0.9240\n",
      "Epoch 161/200\n",
      "Learning rate:  1e-05\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1471 - accuracy: 0.9926 - val_loss: 0.4454 - val_accuracy: 0.9239\n",
      "Epoch 162/200\n",
      "Learning rate:  1e-06\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1454 - accuracy: 0.9933 - val_loss: 0.4467 - val_accuracy: 0.9240\n",
      "Epoch 163/200\n",
      "Learning rate:  1e-06\n",
      "1563/1563 [==============================] - 59s 38ms/step - loss: 0.1487 - accuracy: 0.9923 - val_loss: 0.4460 - val_accuracy: 0.9240\n",
      "Epoch 164/200\n",
      "Learning rate:  1e-06\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1474 - accuracy: 0.9926 - val_loss: 0.4444 - val_accuracy: 0.9245\n",
      "Epoch 165/200\n",
      "Learning rate:  1e-06\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1465 - accuracy: 0.9930 - val_loss: 0.4451 - val_accuracy: 0.9239\n",
      "Epoch 166/200\n",
      "Learning rate:  1e-06\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1470 - accuracy: 0.9925 - val_loss: 0.4429 - val_accuracy: 0.9247\n",
      "Epoch 167/200\n",
      "Learning rate:  1e-06\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1455 - accuracy: 0.9934 - val_loss: 0.4446 - val_accuracy: 0.9240\n",
      "Epoch 168/200\n",
      "Learning rate:  1e-06\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1466 - accuracy: 0.9930 - val_loss: 0.4440 - val_accuracy: 0.9247\n",
      "Epoch 169/200\n",
      "Learning rate:  1e-06\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1465 - accuracy: 0.9925 - val_loss: 0.4425 - val_accuracy: 0.9245\n",
      "Epoch 170/200\n",
      "Learning rate:  1e-06\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1472 - accuracy: 0.9929 - val_loss: 0.4429 - val_accuracy: 0.9252\n",
      "Epoch 171/200\n",
      "Learning rate:  1e-06\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1481 - accuracy: 0.9924 - val_loss: 0.4455 - val_accuracy: 0.9249\n",
      "Epoch 172/200\n",
      "Learning rate:  1e-06\n",
      "1563/1563 [==============================] - 62s 40ms/step - loss: 0.1465 - accuracy: 0.9926 - val_loss: 0.4441 - val_accuracy: 0.9246\n",
      "Epoch 173/200\n",
      "Learning rate:  1e-06\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.1471 - accuracy: 0.9930 - val_loss: 0.4434 - val_accuracy: 0.9243\n",
      "Epoch 174/200\n",
      "Learning rate:  1e-06\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1455 - accuracy: 0.9932 - val_loss: 0.4428 - val_accuracy: 0.9248\n",
      "Epoch 175/200\n",
      "Learning rate:  1e-06\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1466 - accuracy: 0.9925 - val_loss: 0.4431 - val_accuracy: 0.9251\n",
      "Epoch 176/200\n",
      "Learning rate:  1e-06\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1459 - accuracy: 0.9926 - val_loss: 0.4444 - val_accuracy: 0.9254\n",
      "Epoch 177/200\n",
      "Learning rate:  1e-06\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1461 - accuracy: 0.9932 - val_loss: 0.4437 - val_accuracy: 0.9248\n",
      "Epoch 178/200\n",
      "Learning rate:  1e-06\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1451 - accuracy: 0.9930 - val_loss: 0.4441 - val_accuracy: 0.9248\n",
      "Epoch 179/200\n",
      "Learning rate:  1e-06\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1439 - accuracy: 0.9937 - val_loss: 0.4429 - val_accuracy: 0.9256\n",
      "Epoch 180/200\n",
      "Learning rate:  1e-06\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1463 - accuracy: 0.9929 - val_loss: 0.4450 - val_accuracy: 0.9242\n",
      "Epoch 181/200\n",
      "Learning rate:  1e-06\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1453 - accuracy: 0.9931 - val_loss: 0.4429 - val_accuracy: 0.9247\n",
      "Epoch 182/200\n",
      "Learning rate:  5e-07\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.1458 - accuracy: 0.9925 - val_loss: 0.4454 - val_accuracy: 0.9246\n",
      "Epoch 183/200\n",
      "Learning rate:  5e-07\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1459 - accuracy: 0.9928 - val_loss: 0.4443 - val_accuracy: 0.9249\n",
      "Epoch 184/200\n",
      "Learning rate:  5e-07\n",
      "1563/1563 [==============================] - 58s 37ms/step - loss: 0.1459 - accuracy: 0.9922 - val_loss: 0.4456 - val_accuracy: 0.9244\n",
      "Epoch 185/200\n",
      "Learning rate:  5e-07\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1438 - accuracy: 0.9935 - val_loss: 0.4446 - val_accuracy: 0.9253\n",
      "Epoch 186/200\n",
      "Learning rate:  5e-07\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1447 - accuracy: 0.9933 - val_loss: 0.4438 - val_accuracy: 0.9256\n",
      "Epoch 187/200\n",
      "Learning rate:  5e-07\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1452 - accuracy: 0.9930 - val_loss: 0.4456 - val_accuracy: 0.9252\n",
      "Epoch 188/200\n",
      "Learning rate:  5e-07\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1463 - accuracy: 0.9927 - val_loss: 0.4432 - val_accuracy: 0.9249\n",
      "Epoch 189/200\n",
      "Learning rate:  5e-07\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1455 - accuracy: 0.9934 - val_loss: 0.4440 - val_accuracy: 0.9249\n",
      "Epoch 190/200\n",
      "Learning rate:  5e-07\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1454 - accuracy: 0.9928 - val_loss: 0.4430 - val_accuracy: 0.9249\n",
      "Epoch 191/200\n",
      "Learning rate:  5e-07\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1452 - accuracy: 0.9931 - val_loss: 0.4444 - val_accuracy: 0.9251\n",
      "Epoch 192/200\n",
      "Learning rate:  5e-07\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1448 - accuracy: 0.9932 - val_loss: 0.4453 - val_accuracy: 0.9251\n",
      "Epoch 193/200\n",
      "Learning rate:  5e-07\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 0.1446 - accuracy: 0.9937 - val_loss: 0.4466 - val_accuracy: 0.9246\n",
      "Epoch 194/200\n",
      "Learning rate:  5e-07\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1458 - accuracy: 0.9930 - val_loss: 0.4437 - val_accuracy: 0.9254\n",
      "Epoch 195/200\n",
      "Learning rate:  5e-07\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1449 - accuracy: 0.9929 - val_loss: 0.4442 - val_accuracy: 0.9255\n",
      "Epoch 196/200\n",
      "Learning rate:  5e-07\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1465 - accuracy: 0.9920 - val_loss: 0.4438 - val_accuracy: 0.9255\n",
      "Epoch 197/200\n",
      "Learning rate:  5e-07\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1447 - accuracy: 0.9930 - val_loss: 0.4436 - val_accuracy: 0.9256\n",
      "Epoch 198/200\n",
      "Learning rate:  5e-07\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.1463 - accuracy: 0.9926 - val_loss: 0.4458 - val_accuracy: 0.9252\n",
      "Epoch 199/200\n",
      "Learning rate:  5e-07\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1449 - accuracy: 0.9933 - val_loss: 0.4432 - val_accuracy: 0.9250\n",
      "Epoch 200/200\n",
      "Learning rate:  5e-07\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 0.1449 - accuracy: 0.9934 - val_loss: 0.4439 - val_accuracy: 0.9255\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.4439 - accuracy: 0.9255\n",
      "Test loss: 0.4438558518886566\n",
      "Test accuracy: 0.9254999756813049\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "batch_size = 32  # orig paper trained all networks with batch_size=128\n",
    "epochs = 200\n",
    "data_augmentation = True\n",
    "num_classes = 10\n",
    "\n",
    "# Subtracting pixel mean improves accuracy\n",
    "subtract_pixel_mean = True\n",
    "\n",
    "# Model parameter\n",
    "# ----------------------------------------------------------------------------\n",
    "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
    "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
    "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
    "# ----------------------------------------------------------------------------\n",
    "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
    "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
    "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
    "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
    "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
    "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
    "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
    "# ---------------------------------------------------------------------------\n",
    "n = 3\n",
    "\n",
    "# Model version\n",
    "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
    "version = 1\n",
    "\n",
    "# Computed depth from supplied model parameter n\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2\n",
    "\n",
    "input_shape = x_train.shape[1:]    \n",
    "    \n",
    "# Model name, depth and version\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n",
    "\n",
    "x_train.shape[1:]\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=32,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True,decay_count=0):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "    \"\"\"\n",
    "    if kernel_size==1:\n",
    "        conv = Conv2D(num_filters,\n",
    "                      kernel_size=kernel_size,\n",
    "                      strides=strides,\n",
    "                      padding='same',\n",
    "                      kernel_initializer='he_normal',\n",
    "                      kernel_regularizer=l2(1e-4))\n",
    "    else:\n",
    "        conv = zconv2d(num_filters,(0.5-0.0*decay_count),(kernel_size,kernel_size),strides=strides)\n",
    "    \n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_v1(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 1 Model builder [a]\n",
    "\n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    Last ReLU is after the shortcut connection.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filters is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same number of filters.\n",
    "    Features maps sizes:\n",
    "    stage 0: 32x32, 16\n",
    "    stage 1: 16x16, 32\n",
    "    stage 2:  8x8,  64\n",
    "    The Number of parameters is approx the same as Table 6 of [a]:\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # Start model definition.\n",
    "    num_filters = 32\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    # Instantiate the stack of residual units\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides,decay_count=stack)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None,decay_count=stack)\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False,decay_count=stack)\n",
    "            x = tf.keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_v2(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filter maps is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same filter map sizes.\n",
    "    Features maps sizes:\n",
    "    conv1  : 32x32,  16\n",
    "    stage 0: 32x32,  64\n",
    "    stage 1: 16x16, 128\n",
    "    stage 2:  8x8,  256\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    num_filters_in = 32\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate the stack of residual units\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:  # first layer and first stage\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  # first layer but not first stage\n",
    "                    strides = 2    # downsample\n",
    "\n",
    "            # bottleneck residual unit\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = tf.keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "if version == 2:\n",
    "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
    "else:\n",
    "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print(model_type)\n",
    "\n",
    "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
    "\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=model_name,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "\n",
    "callbacks = [checkpoint,lr_reducer,lr_scheduler]\n",
    "\n",
    "# Run training, with or without data augmentation.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # epsilon for ZCA whitening\n",
    "        zca_epsilon=1e-06,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # set range for random shear\n",
    "        shear_range=0.,\n",
    "        # set range for random zoom\n",
    "        zoom_range=0.,\n",
    "        # set range for random channel shifts\n",
    "        channel_shift_range=0.,\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        # value used for fill_mode = \"constant\"\n",
    "        cval=0.,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False,\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    history=model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=epochs, verbose=1, workers=8,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5644afcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T14:27:06.679602Z",
     "iopub.status.busy": "2021-09-01T14:27:06.678915Z",
     "iopub.status.idle": "2021-09-01T14:27:06.888604Z",
     "shell.execute_reply": "2021-09-01T14:27:06.889025Z"
    },
    "papermill": {
     "duration": 42.850843,
     "end_time": "2021-09-01T14:27:06.889167",
     "exception": false,
     "start_time": "2021-09-01T14:26:24.038324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe99899b910>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.plot(np.arange(0, epochs), history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, epochs), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Training Loss on CIRFAR-10\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fd557b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T14:28:33.169585Z",
     "iopub.status.busy": "2021-09-01T14:28:33.154431Z",
     "iopub.status.idle": "2021-09-01T14:28:33.327220Z",
     "shell.execute_reply": "2021-09-01T14:28:33.327588Z"
    },
    "papermill": {
     "duration": 43.477062,
     "end_time": "2021-09-01T14:28:33.327752",
     "exception": false,
     "start_time": "2021-09-01T14:27:49.850690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe99899ba50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(0, epochs), history.history[\"accuracy\"], label=\"train_accuracy\")\n",
    "plt.plot(np.arange(0, epochs), history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.title(\"Accuracy on CIRFAR-10\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11370.803794,
   "end_time": "2021-09-01T14:29:18.482960",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-01T11:19:47.679166",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
